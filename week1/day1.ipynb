{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Website Analysis Demo\n",
    "## Multi-Agent System for Marketing Team Autonomy\n",
    "\n",
    "This demo showcases a working multi-agent system that analyzes websites and provides actionable design recommendations for Marketing teams.\n",
    "\n",
    "### Demo Flow:\n",
    "1. **Web Acquisition Agent** - Fetches and analyzes website structure\n",
    "2. **Analysis Agent** - AI-powered analysis of design patterns and UX issues  \n",
    "3. **Design Suggestion Agent** - Generates Marketing-focused improvement recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Anthropic client\n",
    "try:\n",
    "    client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Anthropic client initialization failed: {e}\")\n",
    "    client = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Web Acquisition Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## ü§ñ Agent 1: Web Acquisition Agent\n",
    "\n",
    "class WebAcquisitionAgent:\n",
    "    \"\"\"Responsible for fetching and analyzing website structure, including CSS and assets.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'\n",
    "        })\n",
    "        self.output_dir = '../sites'\n",
    "\n",
    "    def fetch_website(self, url):\n",
    "        \"\"\"Fetch website content and extract key elements.\"\"\"\n",
    "        print(f\"üîç Web Acquisition Agent: Analyzing {url}\")\n",
    "        \n",
    "        try:\n",
    "            soup = self._get_soup(url)\n",
    "            \n",
    "            # Extract key website elements\n",
    "            analysis = {\n",
    "                'url': url,\n",
    "                'title': soup.find('title').get_text(strip=True) if soup.find('title') else 'No title',\n",
    "                'meta_description': self._get_meta_description(soup),\n",
    "                'html_content': soup.prettify(),\n",
    "                'css_files': self._extract_resources(soup, url, 'link', 'href', 'css', {'rel': 'stylesheet'}),\n",
    "                'js_files': self._extract_resources(soup, url, 'script', 'src', 'js'),\n",
    "                'images': self._extract_images(soup, url),\n",
    "            }\n",
    "            \n",
    "            # Save the full HTML content\n",
    "            self._save_file(url, 'index.html', analysis['html_content'])\n",
    "            \n",
    "            print(\"‚úÖ Website acquisition complete!\")\n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching website: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _get_soup(self, url):\n",
    "        \"\"\"Fetch website content and return a BeautifulSoup object.\"\"\"\n",
    "        response = self.session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    def _get_meta_description(self, soup):\n",
    "        \"\"\"Extract meta description from the HTML.\"\"\"\n",
    "        meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "        return meta_desc.get('content', '') if meta_desc else ''\n",
    "\n",
    "    def _extract_resources(self, soup, base_url, tag, attr, subdir, filter_attrs=None):\n",
    "        \"\"\"Extract and download resources like CSS or JS files.\"\"\"\n",
    "        resources = []\n",
    "        for element in soup.find_all(tag, attrs=filter_attrs):\n",
    "            resource_url = element.get(attr)\n",
    "            if resource_url:\n",
    "                full_url = urljoin(base_url, resource_url)\n",
    "                resources.append(full_url)\n",
    "                self._download_file(full_url, subdir)\n",
    "        return resources\n",
    "\n",
    "    def _extract_images(self, soup, base_url):\n",
    "        \"\"\"Extract image sources and download them.\"\"\"\n",
    "        images = []\n",
    "        for img in soup.find_all('img'):\n",
    "            src = img.get('src', '')\n",
    "            alt = img.get('alt', '')\n",
    "            if src:\n",
    "                full_url = urljoin(base_url, src)\n",
    "                images.append({'src': full_url, 'alt': alt})\n",
    "                self._download_file(full_url, 'images')\n",
    "        return images\n",
    "\n",
    "    def _download_file(self, url, subdir):\n",
    "        \"\"\"Download a file and save it to the appropriate subdirectory.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Create subdirectory if it doesn't exist\n",
    "            dir_path = os.path.join(self.output_dir, subdir)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            \n",
    "            # Save the file\n",
    "            filename = url.split('/')[-1] or 'file'\n",
    "            filepath = os.path.join(dir_path, filename)\n",
    "            with open(filepath, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"‚úÖ Downloaded: {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to download {url}: {str(e)}\")\n",
    "\n",
    "    def _save_file(self, base_url, filename, content):\n",
    "        \"\"\"Save content to a file.\"\"\"\n",
    "        dir_path = os.path.join(self.output_dir, base_url.replace('https://', '').replace('/', '_'))\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        filepath = os.path.join(dir_path, filename)\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(content)\n",
    "        print(f\"‚úÖ Saved: {filepath}\")\n",
    "\n",
    "# Initialize the Web Acquisition Agent\n",
    "web_agent = WebAcquisitionAgent()\n",
    "print(\"ü§ñ Web Acquisition Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test Agent 1:\n",
    "# Ensure the 'sites' directory exists\n",
    "os.makedirs('../sites', exist_ok=True)\n",
    "\n",
    "# Fetch website analysis and write to JSON file\n",
    "url = 'https://www.familysearch.org/en/campaign/temple-ord-ready'\n",
    "analysis = web_agent.fetch_website(url)\n",
    "\n",
    "if analysis:\n",
    "    # Create a valid filename from the URL\n",
    "    filename = url.replace('https://', '').replace('www.', '').replace('/', '_') + '.json'\n",
    "    filepath = os.path.join('../sites', filename)\n",
    "    \n",
    "    # Write analysis to JSON file\n",
    "    with open(filepath, 'w') as json_file:\n",
    "        json.dump(analysis, json_file, indent=4)\n",
    "    \n",
    "    print(f\"‚úÖ Website analysis saved to {filepath}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to fetch website analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Analysis Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## üß† Agent 2: Analysis Agent\n",
    "\n",
    "class AnalysisAgent:\n",
    "    \"\"\"AI-powered analysis of website design patterns and UX issues\"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_client):\n",
    "        self.client = anthropic_client\n",
    "    \n",
    "    def analyze_website(self, website_data):\n",
    "        \"\"\"Analyze website structure and identify design patterns and issues\"\"\"\n",
    "        print(\"üß† Analysis Agent: Processing website data...\")\n",
    "        \n",
    "        # Prepare structured data for AI analysis\n",
    "        analysis_prompt = f\"\"\"\n",
    "        You are a senior UX/UI analyst reviewing a website for a Marketing team. \n",
    "        Analyze the following website data and provide insights on:\n",
    "        1. Overall design patterns and user experience\n",
    "        2. Marketing effectiveness (messaging, CTAs, user journey)\n",
    "        3. Accessibility and usability concerns\n",
    "        4. Content hierarchy and information architecture\n",
    "        \n",
    "        Website Data:\n",
    "        Title: {website_data['title']}\n",
    "        Meta Description: {website_data['meta_description']}\n",
    "        \n",
    "        Headings Structure:\n",
    "        {json.dumps(website_data['headings'], indent=2)}\n",
    "        \n",
    "        Navigation Items: {website_data['navigation'][:10]}\n",
    "        \n",
    "        Call-to-Action Buttons: {website_data['calls_to_action']}\n",
    "        \n",
    "        Forms Present: {len(website_data['forms'])} forms detected\n",
    "        \n",
    "        Images: {len(website_data['images'])} images found\n",
    "        \n",
    "        Content Sections: {len(website_data['content_sections'])} main content areas\n",
    "        \n",
    "        Provide a structured analysis in the following format:\n",
    "        \n",
    "        DESIGN PATTERNS:\n",
    "        - [Key design patterns observed]\n",
    "        \n",
    "        MARKETING EFFECTIVENESS:\n",
    "        - [Assessment of messaging and conversion elements]\n",
    "        \n",
    "        USER EXPERIENCE ISSUES:\n",
    "        - [Potential usability problems]\n",
    "        \n",
    "        ACCESSIBILITY CONCERNS:\n",
    "        - [Basic accessibility observations]\n",
    "        \n",
    "        INFORMATION ARCHITECTURE:\n",
    "        - [Content organization and hierarchy assessment]\n",
    "        \n",
    "        Keep your analysis concise but actionable for a Marketing team.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            analysis_result = response.content[0].text\n",
    "            print(\"‚úÖ Website analysis complete!\")\n",
    "            return analysis_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in analysis: {str(e)}\")\n",
    "            return f\"Analysis failed: {str(e)}\"\n",
    "\n",
    "# Initialize the Analysis Agent  \n",
    "analysis_agent = AnalysisAgent(client)\n",
    "print(\"üß† Analysis Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Design Suggestion Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## üí° Agent 3: Design Suggestion Agent\n",
    "\n",
    "class DesignSuggestionAgent:\n",
    "    \"\"\"Generates Marketing-focused improvement recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_client):\n",
    "        self.client = anthropic_client\n",
    "    \n",
    "    def generate_suggestions(self, website_data, analysis_result):\n",
    "        \"\"\"Generate specific, actionable design improvements for Marketing team\"\"\"\n",
    "        print(\"üí° Design Suggestion Agent: Creating recommendations...\")\n",
    "        \n",
    "        suggestion_prompt = f\"\"\"\n",
    "        You are a Marketing-focused design consultant. Based on the website analysis below, \n",
    "        generate 3-5 specific, actionable recommendations that a Marketing team can implement \n",
    "        to improve conversion rates and user engagement.\n",
    "        \n",
    "        Focus on changes that:\n",
    "        1. Improve messaging clarity and impact\n",
    "        2. Enhance call-to-action effectiveness  \n",
    "        3. Optimize user journey and conversion funnel\n",
    "        4. Address immediate usability issues\n",
    "        5. Strengthen brand positioning\n",
    "        \n",
    "        Previous Analysis:\n",
    "        {analysis_result}\n",
    "        \n",
    "        Website Context:\n",
    "        - Title: {website_data['title']}\n",
    "        - Current CTAs: {website_data['calls_to_action']}\n",
    "        - Navigation: {website_data['navigation'][:5]}\n",
    "        \n",
    "        Provide recommendations in this format:\n",
    "        \n",
    "        üéØ PRIORITY RECOMMENDATIONS:\n",
    "        \n",
    "        1. [RECOMMENDATION TITLE]\n",
    "           Problem: [What specific issue this addresses]\n",
    "           Solution: [Specific actionable change]\n",
    "           Impact: [Expected marketing/conversion benefit]\n",
    "           Implementation: [How Marketing team can execute this]\n",
    "        \n",
    "        2. [Continue for 3-5 recommendations]\n",
    "        \n",
    "        üí∞ CONVERSION IMPACT ESTIMATE:\n",
    "        [Brief assessment of potential conversion improvement]\n",
    "        \n",
    "        üöÄ QUICK WINS:\n",
    "        [1-2 changes that can be implemented immediately]\n",
    "        \n",
    "        Keep recommendations practical and focused on Marketing team capabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=1200,\n",
    "                temperature=0.4,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": suggestion_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            suggestions = response.content[0].text\n",
    "            print(\"‚úÖ Design suggestions generated!\")\n",
    "            return suggestions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating suggestions: {str(e)}\")\n",
    "            return f\"Suggestion generation failed: {str(e)}\"\n",
    "\n",
    "# Initialize the Design Suggestion Agent\n",
    "suggestion_agent = DesignSuggestionAgent(client)\n",
    "print(\"üí° Design Suggestion Agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Demo Value Proposition\n",
    "\n",
    "**What the team just witnessed:**\n",
    "\n",
    "‚úÖ **Multi-Agent System**: 3 specialized AI agents working in coordination  \n",
    "‚úÖ **Real Website Analysis**: Live scraping and analysis of any website  \n",
    "‚úÖ **AI-Powered Insights**: Advanced analysis using Claude 3.5 Sonnet  \n",
    "‚úÖ **Marketing-Focused Output**: Actionable recommendations for Marketing teams  \n",
    "‚úÖ **30-Second Execution**: Rapid analysis that scales to any website  \n",
    "\n",
    "**Immediate Business Value:**\n",
    "- **Time Savings**: Replace hours of manual analysis with 30-second automated insights\n",
    "- **Marketing Autonomy**: Enable Marketing team to analyze competitor sites independently  \n",
    "- **Consistent Analysis**: Standardized evaluation framework across all websites\n",
    "- **Actionable Output**: Specific recommendations, not just generic observations\n",
    "- **Scalability**: Analyze hundreds of websites with the same effort as one\n",
    "\n",
    "**Next Steps:**\n",
    "1. Expand to local website rendering and modification\n",
    "2. Add A/B testing and design option generation  \n",
    "3. Build user-friendly interface for non-technical users\n",
    "4. Integrate with existing Marketing tools and workflows\n",
    "\n",
    "*This demo represents Day 1 of the 2-week development sprint. The foundation is solid and ready for rapid expansion!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ AGENTIC WEBSITE ANALYSIS DEMO\n",
      "==================================================\n",
      "Available demo URLs:\n",
      "  1. https://www.familysearch.org/en/campaign/temple-ord-ready\n",
      "  2. https://anthropic.com\n",
      "  3. https://github.com\n",
      "  4. https://stripe.com\n",
      "\n",
      "To run demo after all agents are initialized:\n",
      "  orchestrator.run_complete_analysis('URL_HERE')\n",
      "==================================================\n",
      "üí° Quick demo function available: quick_demo(1) through quick_demo(4)\n"
     ]
    }
   ],
   "source": [
    "# üöÄ LIVE DEMO - Try It Now!\n",
    "\n",
    "# Demo Configuration\n",
    "DEMO_URLS = [\n",
    "    \"https://www.familysearch.org/en/campaign/temple-ord-ready\",  # Simple, reliable test site\n",
    "    \"https://anthropic.com\",  # AI company with modern design\n",
    "    \"https://github.com\",  # Popular developer platform\n",
    "    \"https://stripe.com\",  # Clean, conversion-focused design\n",
    "]\n",
    "\n",
    "print(\"üöÄ AGENTIC WEBSITE ANALYSIS DEMO\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Available demo URLs:\")\n",
    "for i, url in enumerate(DEMO_URLS, 1):\n",
    "    print(f\"  {i}. {url}\")\n",
    "print(\"\\nTo run demo after all agents are initialized:\")\n",
    "print(\"  orchestrator.run_complete_analysis('URL_HERE')\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Quick demo function for easier testing\n",
    "def quick_demo(url_index=1):\n",
    "    \"\"\"Run demo with one of the predefined URLs\"\"\"\n",
    "    if url_index < 1 or url_index > len(DEMO_URLS):\n",
    "        print(f\"‚ùå Invalid URL index. Choose 1-{len(DEMO_URLS)}\")\n",
    "        return\n",
    "    \n",
    "    url = DEMO_URLS[url_index - 1]\n",
    "    try:\n",
    "        return orchestrator.run_complete_analysis(url)\n",
    "    except NameError:\n",
    "        print(\"‚ùå Error: Please run all agent initialization cells first!\")\n",
    "        print(\"   Required execution order:\")\n",
    "        print(\"   1. Setup cell (imports and dependencies)\")\n",
    "        print(\"   2. Web Acquisition Agent\")\n",
    "        print(\"   3. Analysis Agent\") \n",
    "        print(\"   4. Design Suggestion Agent\")\n",
    "        print(\"   5. Demo Orchestrator\")\n",
    "        print(\"   6. Then you can run demos!\")\n",
    "        return None\n",
    "\n",
    "print(\"üí° Quick demo function available: quick_demo(1) through quick_demo(4)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
