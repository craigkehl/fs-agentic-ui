{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Website Analysis Demo\n",
    "## Multi-Agent System for Marketing Team Autonomy\n",
    "\n",
    "This demo showcases a working multi-agent system that analyzes websites and provides actionable design recommendations for Marketing teams.\n",
    "\n",
    "### Demo Flow:\n",
    "1. **Web Acquisition Agent** - Fetches and analyzes website structure\n",
    "2. **Analysis Agent** - AI-powered analysis of design patterns and UX issues  \n",
    "3. **Design Suggestion Agent** - Generates Marketing-focused improvement recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment setup complete!\n",
      "üìÖ Demo timestamp: 2025-07-02 18:36:57\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Anthropic client\n",
    "try:\n",
    "    client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Anthropic client initialization failed: {e}\")\n",
    "    client = None\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"üìÖ Demo timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Web Acquisition Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## ü§ñ Agent 1: Web Acquisition Agent\n",
    "\n",
    "class WebAcquisitionAgent:\n",
    "    \"\"\"Responsible for fetching and analyzing website structure\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'\n",
    "        })\n",
    "    \n",
    "    def fetch_website(self, url):\n",
    "        \"\"\"Fetch website content and extract key elements\"\"\"\n",
    "        print(f\"üîç Web Acquisition Agent: Analyzing {url}\")\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Extract key website elements\n",
    "            analysis = {\n",
    "                'url': url,\n",
    "                'title': soup.find('title').get_text(strip=True) if soup.find('title') else 'No title',\n",
    "                'meta_description': self._get_meta_description(soup),\n",
    "                'headings': self._extract_headings(soup),\n",
    "                'navigation': self._extract_navigation(soup),\n",
    "                'images': self._extract_images(soup, url),\n",
    "                'calls_to_action': self._extract_ctas(soup),\n",
    "                'content_sections': self._extract_content_sections(soup),\n",
    "                'forms': self._extract_forms(soup)\n",
    "            }\n",
    "            \n",
    "            print(\"‚úÖ Website acquisition complete!\")\n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching website: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_meta_description(self, soup):\n",
    "        meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "        return meta_desc.get('content', '') if meta_desc else ''\n",
    "    \n",
    "    def _extract_headings(self, soup):\n",
    "        headings = {}\n",
    "        for i in range(1, 7):\n",
    "            h_tags = soup.find_all(f'h{i}')\n",
    "            if h_tags:\n",
    "                headings[f'h{i}'] = [h.get_text(strip=True) for h in h_tags[:5]]  # Limit to first 5\n",
    "        return headings\n",
    "    \n",
    "    def _extract_navigation(self, soup):\n",
    "        nav_elements = soup.find_all(['nav', 'ul', 'ol'])\n",
    "        nav_items = []\n",
    "        for nav in nav_elements[:3]:  # Limit to first 3 nav elements\n",
    "            links = nav.find_all('a')\n",
    "            nav_items.extend([link.get_text(strip=True) for link in links[:10]])  # Limit links\n",
    "        return nav_items[:15]  # Total limit\n",
    "    \n",
    "    def _extract_images(self, soup, base_url):\n",
    "        imgs = soup.find_all('img')\n",
    "        images = []\n",
    "        for img in imgs[:10]:  # Limit to first 10 images\n",
    "            src = img.get('src', '')\n",
    "            alt = img.get('alt', '')\n",
    "            if src:\n",
    "                full_url = urljoin(base_url, src)\n",
    "                images.append({'src': full_url, 'alt': alt})\n",
    "        return images\n",
    "    \n",
    "    def _extract_ctas(self, soup):\n",
    "        # Look for common CTA patterns\n",
    "        cta_selectors = ['button', 'a[class*=\"btn\"]', 'a[class*=\"cta\"]', 'input[type=\"submit\"]']\n",
    "        ctas = []\n",
    "        for selector in cta_selectors:\n",
    "            elements = soup.select(selector)\n",
    "            for elem in elements[:5]:  # Limit per selector\n",
    "                text = elem.get_text(strip=True)\n",
    "                if text and len(text) < 50:  # Reasonable CTA length\n",
    "                    ctas.append(text)\n",
    "        return list(set(ctas))[:10]  # Remove duplicates, limit total\n",
    "    \n",
    "    def _extract_content_sections(self, soup):\n",
    "        # Look for main content areas\n",
    "        sections = []\n",
    "        for tag in ['main', 'section', 'article', 'div[class*=\"content\"]']:\n",
    "            elements = soup.select(tag)\n",
    "            for elem in elements[:3]:  # Limit sections\n",
    "                text = elem.get_text(strip=True)\n",
    "                if len(text) > 100:  # Substantial content\n",
    "                    sections.append(text[:200] + '...' if len(text) > 200 else text)\n",
    "        return sections\n",
    "    \n",
    "    def _extract_forms(self, soup):\n",
    "        forms = soup.find_all('form')\n",
    "        form_data = []\n",
    "        for form in forms[:3]:  # Limit forms\n",
    "            inputs = form.find_all(['input', 'select', 'textarea'])\n",
    "            form_info = {\n",
    "                'action': form.get('action', ''),\n",
    "                'method': form.get('method', 'GET'),\n",
    "                'fields': [inp.get('name', inp.get('type', 'unknown')) for inp in inputs[:5]]\n",
    "            }\n",
    "            form_data.append(form_info)\n",
    "        return form_data\n",
    "\n",
    "# Initialize the Web Acquisition Agent\n",
    "web_agent = WebAcquisitionAgent()\n",
    "print(\"ü§ñ Web Acquisition Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Analysis Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## üß† Agent 2: Analysis Agent\n",
    "\n",
    "class AnalysisAgent:\n",
    "    \"\"\"AI-powered analysis of website design patterns and UX issues\"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_client):\n",
    "        self.client = anthropic_client\n",
    "    \n",
    "    def analyze_website(self, website_data):\n",
    "        \"\"\"Analyze website structure and identify design patterns and issues\"\"\"\n",
    "        print(\"üß† Analysis Agent: Processing website data...\")\n",
    "        \n",
    "        # Prepare structured data for AI analysis\n",
    "        analysis_prompt = f\"\"\"\n",
    "        You are a senior UX/UI analyst reviewing a website for a Marketing team. \n",
    "        Analyze the following website data and provide insights on:\n",
    "        1. Overall design patterns and user experience\n",
    "        2. Marketing effectiveness (messaging, CTAs, user journey)\n",
    "        3. Accessibility and usability concerns\n",
    "        4. Content hierarchy and information architecture\n",
    "        \n",
    "        Website Data:\n",
    "        Title: {website_data['title']}\n",
    "        Meta Description: {website_data['meta_description']}\n",
    "        \n",
    "        Headings Structure:\n",
    "        {json.dumps(website_data['headings'], indent=2)}\n",
    "        \n",
    "        Navigation Items: {website_data['navigation'][:10]}\n",
    "        \n",
    "        Call-to-Action Buttons: {website_data['calls_to_action']}\n",
    "        \n",
    "        Forms Present: {len(website_data['forms'])} forms detected\n",
    "        \n",
    "        Images: {len(website_data['images'])} images found\n",
    "        \n",
    "        Content Sections: {len(website_data['content_sections'])} main content areas\n",
    "        \n",
    "        Provide a structured analysis in the following format:\n",
    "        \n",
    "        DESIGN PATTERNS:\n",
    "        - [Key design patterns observed]\n",
    "        \n",
    "        MARKETING EFFECTIVENESS:\n",
    "        - [Assessment of messaging and conversion elements]\n",
    "        \n",
    "        USER EXPERIENCE ISSUES:\n",
    "        - [Potential usability problems]\n",
    "        \n",
    "        ACCESSIBILITY CONCERNS:\n",
    "        - [Basic accessibility observations]\n",
    "        \n",
    "        INFORMATION ARCHITECTURE:\n",
    "        - [Content organization and hierarchy assessment]\n",
    "        \n",
    "        Keep your analysis concise but actionable for a Marketing team.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            analysis_result = response.content[0].text\n",
    "            print(\"‚úÖ Website analysis complete!\")\n",
    "            return analysis_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in analysis: {str(e)}\")\n",
    "            return f\"Analysis failed: {str(e)}\"\n",
    "\n",
    "# Initialize the Analysis Agent  \n",
    "analysis_agent = AnalysisAgent(client)\n",
    "print(\"üß† Analysis Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Design Suggestion Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "## üí° Agent 3: Design Suggestion Agent\n",
    "\n",
    "class DesignSuggestionAgent:\n",
    "    \"\"\"Generates Marketing-focused improvement recommendations\"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_client):\n",
    "        self.client = anthropic_client\n",
    "    \n",
    "    def generate_suggestions(self, website_data, analysis_result):\n",
    "        \"\"\"Generate specific, actionable design improvements for Marketing team\"\"\"\n",
    "        print(\"üí° Design Suggestion Agent: Creating recommendations...\")\n",
    "        \n",
    "        suggestion_prompt = f\"\"\"\n",
    "        You are a Marketing-focused design consultant. Based on the website analysis below, \n",
    "        generate 3-5 specific, actionable recommendations that a Marketing team can implement \n",
    "        to improve conversion rates and user engagement.\n",
    "        \n",
    "        Focus on changes that:\n",
    "        1. Improve messaging clarity and impact\n",
    "        2. Enhance call-to-action effectiveness  \n",
    "        3. Optimize user journey and conversion funnel\n",
    "        4. Address immediate usability issues\n",
    "        5. Strengthen brand positioning\n",
    "        \n",
    "        Previous Analysis:\n",
    "        {analysis_result}\n",
    "        \n",
    "        Website Context:\n",
    "        - Title: {website_data['title']}\n",
    "        - Current CTAs: {website_data['calls_to_action']}\n",
    "        - Navigation: {website_data['navigation'][:5]}\n",
    "        \n",
    "        Provide recommendations in this format:\n",
    "        \n",
    "        üéØ PRIORITY RECOMMENDATIONS:\n",
    "        \n",
    "        1. [RECOMMENDATION TITLE]\n",
    "           Problem: [What specific issue this addresses]\n",
    "           Solution: [Specific actionable change]\n",
    "           Impact: [Expected marketing/conversion benefit]\n",
    "           Implementation: [How Marketing team can execute this]\n",
    "        \n",
    "        2. [Continue for 3-5 recommendations]\n",
    "        \n",
    "        üí∞ CONVERSION IMPACT ESTIMATE:\n",
    "        [Brief assessment of potential conversion improvement]\n",
    "        \n",
    "        üöÄ QUICK WINS:\n",
    "        [1-2 changes that can be implemented immediately]\n",
    "        \n",
    "        Keep recommendations practical and focused on Marketing team capabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=1200,\n",
    "                temperature=0.4,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": suggestion_prompt}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            suggestions = response.content[0].text\n",
    "            print(\"‚úÖ Design suggestions generated!\")\n",
    "            return suggestions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating suggestions: {str(e)}\")\n",
    "            return f\"Suggestion generation failed: {str(e)}\"\n",
    "\n",
    "# Initialize the Design Suggestion Agent\n",
    "suggestion_agent = DesignSuggestionAgent(client)\n",
    "print(\"üí° Design Suggestion Agent initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Demo Value Proposition\n",
    "\n",
    "**What the team just witnessed:**\n",
    "\n",
    "‚úÖ **Multi-Agent System**: 3 specialized AI agents working in coordination  \n",
    "‚úÖ **Real Website Analysis**: Live scraping and analysis of any website  \n",
    "‚úÖ **AI-Powered Insights**: Advanced analysis using Claude 3.5 Sonnet  \n",
    "‚úÖ **Marketing-Focused Output**: Actionable recommendations for Marketing teams  \n",
    "‚úÖ **30-Second Execution**: Rapid analysis that scales to any website  \n",
    "\n",
    "**Immediate Business Value:**\n",
    "- **Time Savings**: Replace hours of manual analysis with 30-second automated insights\n",
    "- **Marketing Autonomy**: Enable Marketing team to analyze competitor sites independently  \n",
    "- **Consistent Analysis**: Standardized evaluation framework across all websites\n",
    "- **Actionable Output**: Specific recommendations, not just generic observations\n",
    "- **Scalability**: Analyze hundreds of websites with the same effort as one\n",
    "\n",
    "**Next Steps:**\n",
    "1. Expand to local website rendering and modification\n",
    "2. Add A/B testing and design option generation  \n",
    "3. Build user-friendly interface for non-technical users\n",
    "4. Integrate with existing Marketing tools and workflows\n",
    "\n",
    "*This demo represents Day 1 of the 2-week development sprint. The foundation is solid and ready for rapid expansion!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ AGENTIC WEBSITE ANALYSIS DEMO\n",
      "==================================================\n",
      "Available demo URLs:\n",
      "  1. https://www.familysearch.org/en/campaign/temple-ord-ready\n",
      "  2. https://anthropic.com\n",
      "  3. https://github.com\n",
      "  4. https://stripe.com\n",
      "\n",
      "To run demo after all agents are initialized:\n",
      "  orchestrator.run_complete_analysis('URL_HERE')\n",
      "==================================================\n",
      "üí° Quick demo function available: quick_demo(1) through quick_demo(4)\n"
     ]
    }
   ],
   "source": [
    "# üöÄ LIVE DEMO - Try It Now!\n",
    "\n",
    "# Demo Configuration\n",
    "DEMO_URLS = [\n",
    "    \"https://www.familysearch.org/en/campaign/temple-ord-ready\",  # Simple, reliable test site\n",
    "    \"https://anthropic.com\",  # AI company with modern design\n",
    "    \"https://github.com\",  # Popular developer platform\n",
    "    \"https://stripe.com\",  # Clean, conversion-focused design\n",
    "]\n",
    "\n",
    "print(\"üöÄ AGENTIC WEBSITE ANALYSIS DEMO\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Available demo URLs:\")\n",
    "for i, url in enumerate(DEMO_URLS, 1):\n",
    "    print(f\"  {i}. {url}\")\n",
    "print(\"\\nTo run demo after all agents are initialized:\")\n",
    "print(\"  orchestrator.run_complete_analysis('URL_HERE')\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Quick demo function for easier testing\n",
    "def quick_demo(url_index=1):\n",
    "    \"\"\"Run demo with one of the predefined URLs\"\"\"\n",
    "    if url_index < 1 or url_index > len(DEMO_URLS):\n",
    "        print(f\"‚ùå Invalid URL index. Choose 1-{len(DEMO_URLS)}\")\n",
    "        return\n",
    "    \n",
    "    url = DEMO_URLS[url_index - 1]\n",
    "    try:\n",
    "        return orchestrator.run_complete_analysis(url)\n",
    "    except NameError:\n",
    "        print(\"‚ùå Error: Please run all agent initialization cells first!\")\n",
    "        print(\"   Required execution order:\")\n",
    "        print(\"   1. Setup cell (imports and dependencies)\")\n",
    "        print(\"   2. Web Acquisition Agent\")\n",
    "        print(\"   3. Analysis Agent\") \n",
    "        print(\"   4. Design Suggestion Agent\")\n",
    "        print(\"   5. Demo Orchestrator\")\n",
    "        print(\"   6. Then you can run demos!\")\n",
    "        return None\n",
    "\n",
    "print(\"üí° Quick demo function available: quick_demo(1) through quick_demo(4)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
